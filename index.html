<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <title>Mateusz Michalkiewicz</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<meta name="google-site-verification" content="4tK5dVI9sx-RXUlNDcZ2kP1z_3U3ogk6Z30cjcNTe6M" />
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Mateusz Michalkiewicz</name>
              </p>
          <p align="justify">I am a Postdoctoral Associate in the <a href="https://eceweb.rice.edu/" target="_blank">Electrical and Computer Engineering (ECE)</a> department at Rice University (Houston, Texas, USA), working with <a href="https://www.guhabalakrishnan.com/" target="_blank">Guha Balakrishnan</a>. 
          <!-- <a href="https://computationalimaging.rice.edu/team/ashok-veeraraghavan/" target="_blank">Ashok Veeraraghavan</a>, and <a href="https://richb.rice.edu/" target="_blank">Richard Baraniuk</a>.  -->
          I received my PhD degree from The University of Queensland (Brisbane, Australia) supervised by <a href="http://aeriksson.net/" target="_blank">Anders Eriksson</a> and <a href="https://researchers.uq.edu.au/researcher/23393" target="_blank">Mahsa Baktashmotlagh</a>. During my PhD, I interned with the computer vision groups at Intel (group of Vladlen Koltun) and NEC-Labs (group of Manmohan Chandraker).  </p>

          <!-- the <a href="https://computationalimaging.rice.edu">Rice Computational Imaging Lab</a>. I finished my Ph.D. from the <a href="http://www.ee.iitm.ac.in/comp_photolab/">Computational Imaging Lab, IITM</a>, where I worked under <a href="http://www.ee.iitm.ac.in/kmitra//">Dr. Kaushik Mitra</a> on computational imaging and computer vision. At the Computational Imaging Lab, I worked on developing novel deep learning-based algorithms and designs for lensless imaging systems. As a Ph.D. candidate, I was awarded the Qualcomm Innovation Fellowship for the year 2020-2021 to work on mask-based lensless cameras. Prior to joining the Ph.D. program at IIT Madras, I completed my undergraduate studies in Electronics and Instrumentation Engineering from the <a href="https://www.nitrkl.ac.in/">National Institute of Technology Rourkela</a>, India. </p> > -->



              <p style="text-align:center">
                      <a href="https://scholar.google.com/citations?user=4uXDXWIAAAAJ&hl=en" target="_blank" >Google Scholar</a> &nbsp/&nbsp
                            <a href="https://dblp.org/pid/182/1773.html" target="_blank" >DBLP</a> &nbsp/&nbsp


                <!-- <a href="mailto:salmansiddique.khan@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/SalmanATSCV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.in/citations?user=FUa7YzYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/siddiquesalman">Github</a> &nbsp/&nbsp
     <a href="https://www.linkedin.com/in/salman-siddique-khan-ph-d-00202b12a"> LinkedIn </a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/matt.jpeg"><img style="width:66%;max-width:100%" alt="profile photo" src="images/matt.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <tr>
      	<td style="padding:20px;width:100%;vertical-align:middle">
      		<p align="left"> <font color="red"><strong>News:</strong></font></p>
      		<ul>
      
          <li> Paper on Viewpoint Instabilities in Vision Foundation Models available on <a href="https://arxiv.org/abs/2412.19920"  target="_blank"   >arxiv</a>! Big pleasure to collaborate with <a href="https://varunjampani.github.io/" target="_blank"  >Varun</a>! </li>
          <li> I will be attending <a href="https://cvpr.thecvf.com/" target="_blank">CVPR 2024</a>. Happy to meet for a coffee! </li>
          <li> DRAGON accepted to  <a href="https://iccp-conference.org/iccp2024/" target="_blank">ICCP 2024</a> </li>
          <li> Visiting <a href="https://aiem.jhu.edu/" target="_blank">Johns Hopkins University, Baltimore</a> in May, 2024 </li>

      		</ul>
      	</td>
      </tr>
   <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
          <heading>Research</heading>
          <p align="justify">
My research interests broadly lie in deep learning and computer vision. Currently, I focus on 3D reconstruction, and domain adaptation/generalization, particularly in the context of models based on implicit neural representations.
Additionally, I am becoming increasingly interested in vision and language models.
 </p>
        </td>
      </tr>

          <!-- PUBLICATIONS BELOW -->
 
      </table>
       <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	   
                <!-- DRAGON -->
        <tr onmouseout="dd_stop()" onmouseover="dd_start()" >
<td style="padding:20px;width:25%;vertical-align:middle">
  <div class="one" style="display: flex; justify-content: center; align-items: center; height: 100%;">
    <img src="images/dragon.png" width="170">
  </div>          
</td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            
            <papertitle><a href="">DRAGON: Drone and Ground Gaussian Splatting for 3D Building Reconstruction
</a></papertitle>
        <br>
        Ham Y, <b>Michalkiewicz M</b>, Balakrishnan G <br>
        <em>International Conference on Computational Photography (ICCP), 2024</em><br>
            <p>We propose a novel view synthesis method for multi-elevation 3D building reconstruction with unknown camera poses </p>
          </td>
        </tr> 

    </tr>   

                    <!-- CODEBOOKS JRNL -->

	<tr onmouseout="tp_stop()" onmouseover="tp_start()" >
<td style="padding:20px;width:25%;vertical-align:middle">
  <div class="one" style="display: flex; justify-content: center; align-items: center; height: 100%;">
    <img src="images/priors.png" width="170">
  </div>          
</td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        
        <papertitle><a href="https://arxiv.org/abs/2106.06440" target="_blank">Learning Compositional Shape Priors for Few-Shot 3D Reconstruction</a></papertitle><br>
        <b>Michalkiewicz M</b>, Tsogkas S, Parisot S, Baktashmotlagh M, Eriksson A, Belilovsky <br>
        <em>Under Submission, 2024</em><br>
        <p>We introduce ShapeNetMini, a small subset of ShapeNet aimed at accelerating model training without sacrificing performance. Additionally, we enhance the performance of existing few-shot 3D reconstruction methods.
 </p>
      </td>
    </tr>

    
                    <!-- GSNR -->

	<tr onmouseout="canopic_stop()" onmouseover="canopic_start()" >
<td style="padding:20px;width:25%;vertical-align:middle">
  <div class="one" style="display: flex; justify-content: center; align-items: center; height: 100%;">
    <img src="images/gsnr.png" width="170">
  </div>          
</td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        
          <papertitle><a href="https://openaccess.thecvf.com/content/ICCV2023/html/Michalkiewicz_Domain_Generalization_Guided_by_Gradient_Signal_to_Noise_Ratio_of_ICCV_2023_paper.html" target="_blank">Domain Generalization Guided by Gradient Signal to Noise Ratio of Parameters</a></papertitle><br>
          <b>Michalkiewicz M</b>, Faraki M, Yu X, Chandraker M, Baktashmotlagh M <br>
        <em>International Conference on Computer Vision (ICCV), 2023</em><br>
        <p>We propose a dropout method leveraging the gradient-signal-to-noise ratio (GSNR) of network's parameters to address overfitting, achieving competitive results on standard domain generalization benchmarks
 </p>
      </td>
    </tr> 


                    <!-- codebooks -->

      <tr onmouseout="pixel_stop()" onmouseover="pixel_start()" >
<td style="padding:20px;width:25%;vertical-align:middle">
  <div class="one" style="display: flex; justify-content: center; align-items: center; height: 100%;">
    <img src="images/fews.png" width="170">
  </div>          
</td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123700613.pdf" target="_blank">Few-Shot Single-View 3-D Object Reconstruction with Compositional Priors</a></papertitle><br>
        <b>Michalkiewicz M</b>, Parisot S, Tsogkas S, Baktashmotlagh M, Eriksson A, Belilovsky <br>
        <em>European Conference on Computer Vision (ECCV), 2020 </em><br>
        <p>We introduce three methods to learn class-specific global shape priors directly from data, tailored for few-shot 3D reconstruction from single images.  </p>
      </td>
    </tr> 

                        <!-- eigensdf -->

      <tr onmouseout="pixel_stop()" onmouseover="pixel_start()" >
<td style="padding:20px;width:25%;vertical-align:middle">
  <div class="one" style="display: flex; justify-content: center; align-items: center; height: 100%;">
    <img src="images/eig.png" width="170">
  </div>          
</td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle><a href="https://www.bmvc2020-conference.com/assets/papers/0443.pdf" target="_blank">A Simple and Scalable Shape Representation for 3D Reconstruction</a></papertitle><br>
        <b>Michalkiewicz M</b>, Belilovsky E, Baktashmotlagh M, Eriksson A <br>
        <em>British Machine Vision Conference (BMBV), 2020 </em><br>
        <p>Our work demonstrates that high-quality 3D reconstruction can be achieved using a linear decoder derived from principal component analysis on the signed distance function (SDF) of the surface, allowing for easy scalability to larger resolutions  </p>
      </td>
    </tr>

                        <!-- implicit layers -->

      <tr onmouseout="pixel_stop()" onmouseover="pixel_start()" >
<td style="padding:20px;width:25%;vertical-align:middle">
  <div class="one" style="display: flex; justify-content: center; align-items: center; height: 100%;">
    <img src="images/imp.png" width="170">
  </div>          
</td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle><a href="https://arxiv.org/abs/2003.01822" target="_blank">Implicitly Defined Layers in Neural Network</a></papertitle><br>
        Zhang Q, Gu Y, <b>Michalkiewicz M</b>, Baktashmotlagh M, Eriksson A <br>
        <em>Preprint, 2020 </em><br>
<p>We demonstrate that defining individual layers in a neural network <em>implicitly</em> provides much richer representations over the standard explicit one, consequently enabling a vastly broader class of end-to-end trainable architectures.</p>
      </td>
    </tr>

                            <!-- deep level sets  -->

      <tr onmouseout="pixel_stop()" onmouseover="pixel_start()" >
<td style="padding:20px;width:25%;vertical-align:middle">
  <div class="one" style="display: flex; justify-content: center; align-items: center; height: 100%;">
    <img src="images/dls.png" width="170">
  </div>          
</td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle><a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Michalkiewicz_Implicit_Surface_Representations_As_Layers_in_Neural_Networks_ICCV_2019_paper.html" target="_blank">Implicit surface representations as layers in neural networks</a></papertitle><br>
        <b>Michalkiewicz M</b>, Pontes JK, Jack D, Baktashmotlagh M, Eriksson A <br>
        <em>International Conference on Computer Vision (ICCV), 2019 </em><br>
        <p>We propose representing 3D shapes implicitly as oriented level sets using a continuous and discretized embedding function within a deep learning framework.   </p>
      </td>
    </tr>


                            <!-- atrophy  -->

      <tr onmouseout="pixel_stop()" onmouseover="pixel_start()" >
      <td style="padding:20px;width:25%;vertical-align:middle">

        <div class="one">
        <div class="two" id = 'pixel_image'><img src='images/med.png' width='170'></div>
        <img src='images/med.png' width='170'>
        </div>



      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle><a href="https://openreview.net/pdf?id=Va6jbkWHln" target="_blank">Combining the boundary shift integral and tensor-based morphometry for brain atrophy estimation.</a></papertitle><br>
        <b>Michalkiewicz M</b>, Pai A, Leung KK, Sommer S, Darkner S, Sorensen L, Sporring
J, Nielsen M <br>
        <em>Medical Imaging (Oral), 2016 </em><br>
        <p>We propose a method for measuring brain atrophy, significantly reducing sample size estimates compared to state-of-the-art techniques  </p>
      </td>
    </tr>

  <!--
  -->





    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website credits to <a href="https://jonbarron.info/">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
</body>

</html>
